---
title: "p8105_hw3_xl3214"
author: "Xuan Lu"
date: "2023-10-11"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Question 1

```{r load dataset & necessary R packages, message = FALSE, results = 'hide'}
library(dplyr)
library(ggplot2)
library(tidyverse)
library(p8105.datasets)
data("instacart")
head(instacart)
summary(instacart)
sum(is.na(instacart))
```

The **instacart** dataset has `r nrow(instacart)` observations and `r ncol(instacart)` variables, including: 

* `order_id`: order identifier, class `r class(pull(instacart, order_id))`.

* `product_id`: product identifier, class `r class(pull(instacart, product_id))`.

* `add_to_cart_order`: order in which each product was added to cart, class `r class(pull(instacart, add_to_cart_order))`.

* `reordered`: 1 if this prodcut has been ordered by this user in the past, 0 otherwise, class `r class(pull(instacart, reordered))`.

* `user_id`: customer identifier, class `r class(pull(instacart, user_id))`.

* `eval_set`: which evaluation set this order belongs in (Note that the data for use in this class is exclusively from the “train” eval_set), class `r class(pull(instacart, eval_set))`.

* `order_number`: the order sequence number for this user (1=first, n=nth), class `r class(pull(instacart, order_number))`.

* `order_dow`: the day of the week on which the order was placed, class `r class(pull(instacart, order_dow))`.

* `order_hour_of_day`: the hour of the day on which the order was placed, class `r class(pull(instacart, order_hour_of_day))`.

* `days_since_prior_order`: days since the last order, capped at 30, NA if order_number=1, class `r class(pull(instacart, days_since_prior_order))`.

* `product_name`: name of the product, class `r class(pull(instacart, product_name))`.

* `aisle_id`: aisle identifier, class `r class(pull(instacart, aisle_id))`.

* `department_id`: department identifier, class `r class(pull(instacart, department_id))`.

* `aisle`: the name of the aisle, class `r class(pull(instacart, aisle))`.

* `department`: the name of the department, class `r class(pull(instacart, department))`.

```{r Explore key variables, message = FALSE, echo = FALSE}
#Summary of unique users
users_sum <- instacart |> 
  group_by(user_id) |> 
  summarize(n_obs = n())

#Summary of unique orders
orders_sum <- instacart |> 
  group_by(order_id) |> 
  summarize(n_obs = n())

#Summary of aisles
aisle_sum <- instacart |> 
  group_by(aisle) |> 
  summarize(n_obs = n())

#Summary of departments
department_sum <- instacart |> 
  group_by(department) |> 
  summarize(n_obs = n())

#Summary of sales by the day of the week on which the order was placed
sum_dow <- instacart |>
  group_by(order_dow) |>
  summarize(n_obs = n())
sum_dow
```

  * There are `r nrow(users_sum)` unique users and `r nrow(orders_sum)` unique orders. On average, there are `r mean(pull(sum_dow,n_obs))` items sold per day. There are `r length(unique(pull(aisle_sum, aisle)))` aisles and `r length(unique(pull(department_sum, department)))` departments. Below are some graphs to help visualize the dataset key variables.

```{r Q1- Some basic visualizations, echo = FALSE, message = FALSE}
#number of unique orders and distribution of total items purchased per order, colored by unique users
instacart |> 
  group_by(order_id) |> 
  summarize(n_obs = n()) |> 
  ggplot(aes(x = n_obs)) + 
  geom_histogram(color = "blue", fill = "lightblue") + 
  labs(
    title = "Orders Histogram",
    x = "Unique Order ID",
    y = "Number of Items (Count)"
  )

#departments, in barplot
instacart |> ggplot(aes(y = department)) +
  geom_bar(color = "blue", fill = "lightblue") +
  labs(title ="Department Barplot",
       y ='Department',
       x ='Frequency'
      ) + 
  theme(axis.text.y=element_text(size=10))

#aisles, in barplot
instacart |> ggplot(aes(x = aisle_id)) +
  geom_bar(color = "blue", fill = "lightblue") +
  labs(title = "Aisle Barplot",
       x ='Unique Aisle ID',
       y ='Frequency'
      )

#aisles barplot, colored by departments
instacart |> 
  ggplot(aes(x = aisle_id, color = department, fill = department)) + 
  geom_bar(position = "dodge") + 
  labs(title = "Aisles Histogram",
       x = "Unique Aisle ID",
       y = "Number of Items (Count)"
      ) + 
  theme(legend.position = "top")
```

1. How many aisles are there, and which aisles are the most items ordered from?

  * Answer: There are `r length(unique(pull(instacart, aisle)))` aisles, and most items are ordered from aisle *`r filter(aisle_sum, n_obs == max(pull(aisle_sum,n_obs))) |> select(aisle)`*.

2. Make a plot that shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered. Arrange aisles sensibly, and organize your plot so others can read it.

```{r Q1- Making the aisle plot, echo = FALSE}
#aisles, in barplot
aisle_for_plot <- instacart |>
  group_by(aisle) |>
  summarize(n_obs = n()) |>
  filter(n_obs > 10000)

aisle_for_plot |>
  ggplot(aes(y = aisle, x = n_obs)) +
  geom_point() +
  labs(title = "Aisle Scatterplot",
       x ='Number of Items Purchased',
       y ='Aisle'
      ) + 
  theme(axis.text.y=element_text(size=8))
```

  * There are `r length(unique(pull(aisle_for_plot, aisle)))` aisles with more than 10,000 items ordered. 
  
  * Most aisles have less than 40,000 items ordered. There are 5 aisles that have more than 40,000 items sold. They are: `r pull(filter(aisle_for_plot, n_obs > 40000), aisle)`.
  

3. Make a table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”. Include the number of times each item is ordered in your table.

```{r Making the table showing three most popular items, message = FALSE, echo = FALSE}
aisle_for_table <- instacart |>
  filter(aisle == "baking ingredients" | aisle == "dog food care" | aisle == "packaged vegetables fruits") |>
  group_by(aisle, product_name) |>
  summarize(n_obs = n()) |>
  filter(n_obs %in% tail(sort(n_obs), 3)) |>
  arrange(desc(n_obs))
aisle_for_table
```

  * For aisle *packaged vegetables fruits*, products `r pull(filter(aisle_for_table, aisle == "packaged vegetables fruits"), product_name)` are the three most popular products, each correspond to `r pull(filter(aisle_for_table, aisle == "packaged vegetables fruits"), n_obs)` in sales.

  * For aisle *baking ingredients*, products `r pull(filter(aisle_for_table, aisle == "baking ingredients"), product_name)` are the three most popular products, each correspond to `r pull(filter(aisle_for_table, aisle == "baking ingredients"), n_obs)` in sales.
  
  * For aisle *dog food care*, products `r pull(filter(aisle_for_table, aisle == "dog food care"), product_name)` are the three most popular products, each correspond to `r pull(filter(aisle_for_table, aisle == "dog food care"), n_obs)` in sales.
  
  * Among the three aisles, `r aisle_for_table[which.max(pull(aisle_for_table, n_obs)), 2]` has the most sales of `r max(pull(aisle_for_table, n_obs))`.


4. Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week; format this table for human readers (i.e. produce a 2 x 7 table).

```{r Making the table for mean hour of day, message = FALSE, echo = FALSE}
aisle_for_table_2 <- instacart |>
  filter(product_name == "Pink Lady Apples" | product_name == "Coffee Ice Cream") |>
  group_by(order_dow) |>
  mutate(mean_hour = mean(order_hour_of_day, na.rm = TRUE)) |>
  distinct(order_dow, mean_hour) |>
  arrange(order_dow) |>
  mutate(order_dow = recode(order_dow, "0" = "Sun", "1" = "Mon", "2" = "Tue", 
                            "3" = "Wed", "4" = "Thurs", "5" = "Fri", "6" = "Sat")) |>
  pivot_wider(names_from = "order_dow", values_from = "mean_hour")
aisle_for_table_2
```
  
  * `r colnames(aisle_for_table_2[max.col(aisle_for_table_2,ties.method="first")])` has the latest mean hour of day at which Pink Lady Apples and Coffee Ice Cream are ordered. 


## Question 2
```{r load dataset, message = FALSE, results = 'hide'}
data("brfss_smart2010")
sum(is.na(brfss_smart2010))
```

```{r data cleaning, results = 'hide', message = FALSE}
#format the data to use appropriate variable names
#focus on the “Overall Health” topic, include only responses from “Excellent” to “Poor”
#organize responses as a factor taking levels ordered from “Poor” to “Excellent”
brfss <- brfss_smart2010 |>
  janitor::clean_names() |> 
  filter(topic == "Overall Health" & response %in% c("Excellent", "Very good", "Good", "Fair", "Poor")) |> 
  mutate(response = factor(response, 
                           levels=c("Poor", "Fair", "Good", "Very good", "Excellent"), ordered=TRUE)) |>
  rename(resp_id = respid, location_abbr = locationabbr, location_desc = locationdesc)

head(brfss)
sum(is.na(brfss))
```

After cleaning, the BRFSS dataset has `r nrow(brfss)` observations and `r ncol(brfss)` variables. Variables include: `r colnames(brfss)`. The type of data value in this dataset is `r distinct(brfss, data_value_type)`, and the unit of data value is `r distinct(brfss, data_value_unit)`. The topic of focus is `r unique(pull(brfss, topic))`, question is `r unique(pull(brfss, question))`, and responses include `r unique(pull(brfss, response))`.

1. In 2002, which states were observed at 7 or more locations? What about in 2010?

```{r results = 'hide', message = FALSE, echo = FALSE}
brfss_q1 <- brfss |> 
  group_by(year) |> 
  select(year, location_abbr, location_desc) |>
  distinct(year, location_abbr, location_desc) |>
  group_by(year, location_abbr) |>
  summarise(n_obs = n())
sum(is.na(brfss_q1))
```

  * In 2002, `r pull(filter(brfss_q1, year == "2002" & n_obs > 7), location_abbr)` states were observed at 7 or more locations. 
  
  * In 2010, `r pull(filter(brfss_q1, year == "2010" & n_obs > 7), location_abbr)` states were observed at 7 or more locations. 
  
  * From 2002 to 2010, there is a significant increase in the number of states that have 7 or more observation locations. 

2. Construct a dataset that is limited to Excellent responses, and contains, year, state, and a variable that averages the data_value across locations within a state. Make a “spaghetti” plot of this average value over time within a state (that is, make a plot showing a line for each state across years – the geom_line geometry and group aesthetic will help).

```{r Q2- Spaghetti Plot, echo = FALSE, warning = FALSE}
brfss_q2 <- brfss |> 
  filter(response == "Excellent") |>
  group_by(year, location_abbr) |> 
  mutate(data_value_state_avg = mean(data_value)) |>
  select(year, location_abbr, data_value_state_avg) |>
  distinct(year, location_abbr, data_value_state_avg)
brfss_q2
check_na <- which(is.na(brfss_q2))
brfss_q2[check_na,]

ggplot(brfss_q2, aes(x = year, y = data_value_state_avg, color = location_abbr)) + 
  geom_line() +
  labs(title = "Spaghetti Plot: Yearly Average Crude Prevalence, by State",
       x = "Year",
       y = "Average Crude Prevalence (%)"
      )
```

  * The average crude prevalence across locations within a state fluctuates across years, but overall remains fairly stable. There is no distinguishable trend in the average data values across years. 
  
  * Among all data available, `r brfss_q2[which.max(pull(brfss_q2,data_value_state_avg)), 2]` in `r brfss_q2[which.max(pull(brfss_q2,data_value_state_avg)), 1]` has the highest average crude prevalence, `r brfss_q2[which.min(pull(brfss_q2,data_value_state_avg)), 2]` in `r brfss_q2[which.min(pull(brfss_q2,data_value_state_avg)), 1]` has the lowest average crude prevalence.

3. Make a two-panel plot showing, for the years 2006, and 2010, distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY State.

```{r Q2- Two-panel plot, echo = FALSE, warning = FALSE}
brfss_q3 <- brfss |>
  filter(location_abbr == "NY" & year %in% c("2006", "2010")) |>
  select(year, location_desc, response, data_value)

#Graph 1: without coloring by county
ggplot(brfss_q3, aes(x = response, y = data_value)) + 
  geom_boxplot(outlier.colour="black", outlier.shape=16,
             outlier.size=2, notch=FALSE) + 
  facet_grid(. ~ year) +
  labs(
    title = "Box Plot: Crude Prevalence for Responses in NY State, 2006 vs. 2010",
       x = "Response",
       y = "Crude Prevalence (%)"
      ) + 
  theme(
    title = element_text(size=10),
    axis.text.x = element_text(size=7))

#Graph 2: with coloring by county
ggplot(brfss_q3, aes(x = response, y = data_value, color = location_desc)) + 
  geom_point() + 
  facet_grid(. ~ year) +
  labs(
    title = "Scatter Plot: Crude Prevalence for Responses among Locations in NY State, 2006 vs. 2010",
       x = "Response",
       y = "Crude Prevalence (%)"
      ) + 
  theme(
    title = element_text(size=10),
    axis.text.x = element_text(size=7))
```

  * Based on the plots, we can see that *Poor* responses correspond to the lowest crude prevalence across all locations in NY State for both 2006 and 2010, and as the order of responses increases towards *Very good*, the crude prevalence also increases. However, for responses of *Excellent*, we see a decreased crude prevalence distribution compared to the previous *Good* and *Very good*. 
  
  * We can see that in 2006, responses *Good* and *Very good* have comparable crude prevalence distributions, although the median for *Very good* is slightly higher. When it comes to 2010, the crude prevalence for responses *Very good* is apparently higher than that of *Good*. Responses *Fair* and *Poor* in 2010 have wider spread compared to that of 2006.

## Question 3

1. Load, tidy, merge, and otherwise organize the data sets. Your final dataset should include all originally observed variables; exclude participants less than 21 years of age, and those with missing demographic data; and encode data with reasonable variable classes (i.e. not numeric, and using factors with the ordering of tables and plots in mind).

```{r Q3- Read-in demographic dataset and cleaning, message = FALSE, results = 'hide'}
#Checking variable descriptions (first few rows)
covar_desc <- read_csv(file = "./nhanes_covar.csv", col_names = FALSE)
covar_desc <- covar_desc[1:4,]
covar_desc

covar <- read_csv(file = "./nhanes_covar.csv", skip = 4, col_names = TRUE) |> 
  janitor::clean_names() |> 
  mutate(sex = recode(sex, "1" = "male", "2" = "female")) |>
  mutate(education = recode(education, "1" = "Less than high school", "2" = "High school equivalent", "3" = "More than high school")) |>
  mutate(education = factor(education, levels=c("Less than high school", "High school equivalent", "More than high school"), ordered=TRUE)) |>
  filter(age >= 21) |>
  na.omit()

head(covar)
sum(is.na(covar))
```

```{r Q3- Read-in accelerometer dataset and cleaning, message = FALSE, results = 'hide'}
accel <- read_csv(file = "./nhanes_accel.csv") |>
  janitor::clean_names()
```

```{r Q3- Merge the two datasets to form a final dataset, message = FALSE, results = 'hide'}
q3_merged <- left_join(covar, accel)
q3_merged
summary(q3_merged)
```

  * There are `r nrow(q3_merged)` participants in the study, and the merged dataset has `r ncol(q3_merged)` variables, after excluding participants less than 21 years of age and those with missing demographic data. 

2. Produce a reader-friendly table for the number of men and women in each education category, and create a visualization of the age distributions for men and women in each education category. Comment on these items.

```{r Q3- sex in each education cat and age distribution, echo = FALSE}
#Create table for the number of men and women in each education category
sex_education_df <- q3_merged |>
  group_by(education, sex) |> 
  summarise(n_obs = n())
sex_education_df

#Create visualization of the age distributions for men and women in each education category
ggplot(q3_merged, aes(x = age, y = education)) +
  geom_boxplot(outlier.colour="black", outlier.shape=16,
             outlier.size=2, notch=FALSE) +
  facet_grid(. ~ sex) +
  labs(
    title = "Box Plot: Age Distribution in Each Education Level, by Gender",
       y = "Education Level",
       x = "Age"
      ) + 
  theme(
    title = element_text(size=10),
    axis.text.x = element_text(size=10), 
    axis.text.y = element_text(size=10))
```

  * Based on the table, for education levels of *Less than high school* and *More than high school*, male and female have similar number of participants. For *High school equivalent* education level, however, there are much more males compared to females. 
  
  * Age distribution for different education level is similar across genders. Again, difference between genders is only apparent for *High school equivalent* education level, where the minimum, maximum, and mean age of female is higher than male.

3. Traditional analyses of accelerometer data focus on the total activity over the day. Using your tidied dataset, aggregate across minutes to create a total activity variable for each participant. Plot these total activities (y-axis) against age (x-axis); your plot should compare men to women and have separate panels for each education level. Include a trend line or a smooth to illustrate differences. Comment on your plot.

```{r Q3- calculate total mims and plot it against age, echo = FALSE}
#aggregate across minutes to create total activity variable, "total_mims"
analysis_total <- q3_merged |> select(min1:min1440)

analysis_total <- q3_merged |> 
  mutate(total_mims = rowSums(analysis_total, na.rm = TRUE)) |>
  select(seqn, sex, age, education, total_mims)

ggplot(analysis_total, aes(x = age, y = total_mims, color = sex)) +
  geom_point(alpha = 0.5) +
  geom_smooth(aes(group = sex), se = FALSE) +
  facet_grid(. ~ education) +
  labs(
    title = "Total Activity Distribution by Age and Gender, Grouped by Education Level",
       y = "Total Activity (MIMS)",
       x = "Age"
      ) + 
  theme(
    title = element_text(size=10),
    axis.text.x = element_text(size=10), 
    axis.text.y = element_text(size=10),
    legend.position = "top")
```

  * Overall, total activity decreases as age increases, consistent across all education levels and genders. This trend is most apparent among those with less than high school education, and least apparent among those with more than high school education. 
  
  * For those with less than high school education, total activity decreases as age proceed from 21 to 50, then increases as age proceed from 50 to 60, then decreases again as age continues to increase. Males have more increase from age 50 to 60 than female.
  
  * For those with high school equivalent education, total activity increases as age proceed from 21 to 40, then decreases as age continues to proceed. For females, total activity increases again from age 60 to 70, then decreases again. For males, total activity plateaus starting age 60. 
  
  * For those with more than high school education, total activity plateaus from age 21 to 40. For females, total activity increases slightly as age proceed from 40 to 45, then decreases starting 50. For males, total activity plateaus from 21 to 50, increases slightly from 50 to 60, then decreases starting 60.

4. Accelerometer data allows the inspection activity over the course of the day. Make a three-panel plot that shows the 24-hour activity time courses for each education level and use color to indicate sex. Describe in words any patterns or conclusions you can make based on this graph; including smooth trends may help identify differences.

```{r Q3- 24-hour activity time courses for each education level and sex, echo = FALSE}
#Prep dataset for plotting, i.e., change variables min1:min1440 to rows and change "min1" to 1
analysis_time_course <- q3_merged |> 
  pivot_longer(min1:min1440, names_to = "minute", values_to = "mims") |>
  group_by(seqn) |>
  mutate(minute = as.numeric(str_replace(minute, "min", "")))

ggplot(analysis_time_course, aes(x = minute, y = mims, color = sex)) +
  geom_smooth(aes(group = sex), se = FALSE) +
  facet_grid(. ~ education) +
  labs(
    title = "24-Hour Activity Time Courses by Minute and Sex, Grouped by Education Level",
       x = "Minute of Day",
       y = "Activity per Minute (MIMS/min)"
      ) + 
  theme(
    title = element_text(size=10),
    axis.text.x = element_text(size=10), 
    axis.text.y = element_text(size=10),
    legend.position = "right")
```

  * In a 24-hour time window, activity level first decreases in the early morning (0 to 250 minutes or  0 to `r 250/60` hours of day), sharply increases starting at 250 minutes or `r 250/60` hours of day, reaches its peak 500 to 10200 minutes or `r 500/60` to `r 10200/60` hours of day, and sharply decreases starting at 10200 minutes or `r 10200/60` hours of day. This trend is observed across education levels and sex. Female has higher activity level peak than males, across all education levels. 
  
  * The activity peak for those with less than high school education is highest for both genders compared to the other two education level groups. This group decreases sharply after it reaches its peak activity level, consistent across genders.
  
  * The activity peak for those with high school equivalent education is the lowest for both genders compared to the other to education level groups. After reaching to its peak, this group plateaus (slightly decreases) from 500 to 10200 minutes or `r 500/60` to `r 10200/60` hours of day, then sharply decreases afterwards.
  
  * The activity peak for those with more than high school education plateaus the longest, particularly for males. 



